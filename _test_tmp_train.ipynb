{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class opt():\n",
    "    hparamDatasetPath = r\"G:\\01_DATA\\022_UPC\\Project\\_kitti_test\\data_odometry_velodyne\\dataset\\sequences\",\n",
    "    hparamYamlConfigPath = \"F0_Visualization\\semantic-kitti-api\\config\\semantic-kitti.yaml\",\n",
    "    hparamNumberOfRandomPoints = 4000\n",
    "    hparamDatasetSequence = '04'    \n",
    "    hparamNumberOfClasses = 34\n",
    "    hparamBatchSize = 32\n",
    "    hparamNumberOfEpochs = 250 #TODO: add to config ?\n",
    "    hparamNumberOfWorkers = 4 #TODO: add to config ?\n",
    "    hparamOutputFolder = 'cls' #TODO: add to config ?\n",
    "    hparamDeviceType = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PD_user\\miniconda3\\envs\\ml_test\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "271 271\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from B0_Dataset.dataset import SemanticKittiDataset\n",
    "from D0_Modeling.model import PointNetCls, feature_transform_regularizer\n",
    "#from A0_Configuration.hyperparam import Parsing\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from B1_Dataloader.dataloader import DataLoader_\n",
    "\n",
    "#parser = argparse.ArgumentParser()\n",
    "#parser.add_argument('--batchSize', type=int, default=32, help='input batch size')\n",
    "#parser.add_argument('--num_points', type=int, default=2500, help='input batch size')\n",
    "#parser.add_argument('--workers', type=int, help='number of data loading workers', default=4)\n",
    "#parser.add_argument('--nepoch', type=int, default=250, help='number of epochs to train for')\n",
    "#parser.add_argument('--outf', type=str, default='cls', help='output folder')\n",
    "#parser.add_argument('--model', type=str, default='', help='model path')\n",
    "#parser.add_argument('--dataset', type=str, required=True, help=\"dataset path\")\n",
    "#parser.add_argument('--dataset_type', type=str, default='SemanticKitti', help=\"dataset type\")\n",
    "#parser.add_argument('--feature_transform', action='store_true', help=\"use feature transform\")\n",
    "#opt = parser.parse_args()\n",
    "#print(opt)\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--batchSize', type=int, default=32, help='input batch size')\n",
    "# parser.add_argument('--num_points', type=int, default=2500, help='input batch size')\n",
    "# parser.add_argument('--workers', type=int, help='number of data loading workers', default=0)\n",
    "# parser.add_argument('--nepoch', type=int, default=250, help='number of epochs to train for')\n",
    "# parser.add_argument('--outf', type=str, default='cls', help='output folder')\n",
    "# parser.add_argument('--model', type=str, default='', help='model path')\n",
    "# parser.add_argument('--dataset', type=str, default='/content/data/dataset/', help=\"dataset path\")\n",
    "# parser.add_argument('--dataset_type', type=str, default='SemanticKitti', help=\"dataset type\")\n",
    "# parser.add_argument('--feature_transform', action='store_true', help=\"use feature transform\")\n",
    "# parser.add_argument(\"-f\", \"--file\", required=False) \n",
    "# opt = parser.parse_args()\n",
    "# print(opt)\n",
    "\n",
    "blue = lambda x: '\\033[94m' + x + '\\033[0m'\n",
    "\n",
    "#opt.manualSeed = random.randint(1, 10000)\n",
    "#print(\"Random Seed: \", opt.manualSeed)\n",
    "#random.seed(opt.manualSeed)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = SemanticKittiDataset(\n",
    "    data_catalog_path=opt.hparamDatasetPath[0],\n",
    "    sequence_number=opt.hparamDatasetSequence,\n",
    "    yaml_config_path=opt.hparamYamlConfigPath[0],\n",
    "    n_points=opt.hparamNumberOfRandomPoints,\n",
    "    action_type='train')\n",
    "\n",
    "test_dataset = SemanticKittiDataset(\n",
    "    data_catalog_path=opt.hparamDatasetPath[0],\n",
    "    sequence_number=opt.hparamDatasetSequence,\n",
    "    yaml_config_path=opt.hparamYamlConfigPath[0],\n",
    "    n_points=opt.hparamNumberOfRandomPoints,\n",
    "    action_type='test')\n",
    "\n",
    "train_dataloader = DataLoader_(\n",
    "    dataset= train_dataset,\n",
    "    batch_size=opt.hparamBatchSize,\n",
    "    shuffle=True,\n",
    "    num_workers=int(opt.hparamNumberOfWorkers)\n",
    ")\n",
    "test_dataloader = DataLoader_(\n",
    "    dataset = test_dataset,\n",
    "    batch_size=opt.hparamBatchSize,\n",
    "    shuffle=True,\n",
    "    num_workers=int(opt.hparamNumberOfWorkers))\n",
    "\n",
    "print(len(train_dataset), len(test_dataset))\n",
    "\n",
    "try:\n",
    "    os.makedirs(opt.hparamOutputFolder)\n",
    "except OSError:\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PD_user\\miniconda3\\envs\\ml_test\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:138: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0: 0/8] train loss: 3.460122 accuracy: 0.031250\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 43\u001b[0m\n\u001b[0;32m     41\u001b[0m points, target \u001b[39m=\u001b[39m points\u001b[39m.\u001b[39mto(opt\u001b[39m.\u001b[39mhparamDeviceType), target\u001b[39m.\u001b[39mto(opt\u001b[39m.\u001b[39mhparamDeviceType)\n\u001b[0;32m     42\u001b[0m classifier \u001b[39m=\u001b[39m classifier\u001b[39m.\u001b[39meval()\n\u001b[1;32m---> 43\u001b[0m pred, _, _ \u001b[39m=\u001b[39m classifier(points)\n\u001b[0;32m     44\u001b[0m loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mnll_loss(pred, target)\n\u001b[0;32m     45\u001b[0m pred_choice \u001b[39m=\u001b[39m pred\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mmax(\u001b[39m1\u001b[39m)[\u001b[39m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\PD_user\\miniconda3\\envs\\ml_test\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mg:\\01_DATA\\022_UPC\\Project\\_kitti_test\\workspace_AD_LiDAR_v0.3\\Workspace-AD-LiDAR\\Workspace-AD-LiDAR\\D0_Modeling\\model.py:148\u001b[0m, in \u001b[0;36mPointNetCls.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m--> 148\u001b[0m     x, trans, trans_feat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeat(x)\n\u001b[0;32m    149\u001b[0m     x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn1(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc1(x)))\n\u001b[0;32m    150\u001b[0m     x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn2(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc2(x))))\n",
      "File \u001b[1;32mc:\\Users\\PD_user\\miniconda3\\envs\\ml_test\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mg:\\01_DATA\\022_UPC\\Project\\_kitti_test\\workspace_AD_LiDAR_v0.3\\Workspace-AD-LiDAR\\Workspace-AD-LiDAR\\D0_Modeling\\model.py:109\u001b[0m, in \u001b[0;36mPointNetfeat.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m    108\u001b[0m     n_pts \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39msize()[\u001b[39m2\u001b[39m]\n\u001b[1;32m--> 109\u001b[0m     trans \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstn(x)\n\u001b[0;32m    110\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mtranspose(\u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m    111\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mbmm(x, trans)\n",
      "File \u001b[1;32mc:\\Users\\PD_user\\miniconda3\\envs\\ml_test\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mg:\\01_DATA\\022_UPC\\Project\\_kitti_test\\workspace_AD_LiDAR_v0.3\\Workspace-AD-LiDAR\\Workspace-AD-LiDAR\\D0_Modeling\\model.py:37\u001b[0m, in \u001b[0;36mSTN3d.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     35\u001b[0m batchsize \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39msize()[\u001b[39m0\u001b[39m]\n\u001b[0;32m     36\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn1(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1(x)))\n\u001b[1;32m---> 37\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn2(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv2(x)))\n\u001b[0;32m     38\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn3(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv3(x)))\n\u001b[0;32m     39\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(x, \u001b[39m2\u001b[39m, keepdim\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\PD_user\\miniconda3\\envs\\ml_test\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\PD_user\\miniconda3\\envs\\ml_test\\lib\\site-packages\\torch\\nn\\modules\\conv.py:313\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32mc:\\Users\\PD_user\\miniconda3\\envs\\ml_test\\lib\\site-packages\\torch\\nn\\modules\\conv.py:309\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    306\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv1d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    307\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    308\u001b[0m                     _single(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 309\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv1d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    310\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# classifier = PointNetCls(k=num_classes, feature_transform=opt.feature_transform)\n",
    "classifier = PointNetCls(k=opt.hparamNumberOfClasses, feature_transform=False)\n",
    "\n",
    "# if opt.model != '':\n",
    "#     classifier.load_state_dict(torch.load(opt.model)) #TODO: use if we plan to load model\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "classifier = classifier.to(opt.hparamDeviceType)\n",
    "\n",
    "num_batch = len(train_dataset) / opt.hparamBatchSize #FIXME: is it ok?\n",
    "\n",
    "\n",
    "for epoch in range(opt.hparamNumberOfEpochs):\n",
    "    scheduler.step()\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        points, target = data\n",
    "        target = target[:, 0]\n",
    "        points = points.transpose(2, 1)\n",
    "        # points, target = points.cuda(), target.cuda()\n",
    "        points, target = points.to(opt.hparamDeviceType), target.to(opt.hparamDeviceType)\n",
    "        optimizer.zero_grad()\n",
    "        classifier = classifier.train()\n",
    "        pred, trans, trans_feat = classifier(points)\n",
    "        loss = F.nll_loss(pred, target)\n",
    "        # loss = nn.NNLLoss(pred, target)\n",
    "        # if opt.feature_transform:\n",
    "        #     loss += feature_transform_regularizer(trans_feat) * 0.001 :FIXME If we like to use feature transform\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pred_choice = pred.data.max(1)[1]\n",
    "        correct = pred_choice.eq(target.data).cpu().sum()\n",
    "        print('[%d: %d/%d] train loss: %f accuracy: %f' % (epoch, i, num_batch, loss.item(), correct.item() / float(opt.hparamBatchSize)))\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            j, data = next(enumerate(test_dataloader, 0))\n",
    "            points, target = data\n",
    "            target = target[:, 0]\n",
    "            points = points.transpose(2, 1)\n",
    "            # points, target = points.cuda(), target.cuda()\n",
    "            points, target = points.to(opt.hparamDeviceType), target.to(opt.hparamDeviceType)\n",
    "            classifier = classifier.eval()\n",
    "            pred, _, _ = classifier(points)\n",
    "            loss = F.nll_loss(pred, target)\n",
    "            pred_choice = pred.data.max(1)[1]\n",
    "            correct = pred_choice.eq(target.data).cpu().sum()\n",
    "            print('[%d: %d/%d] %s loss: %f accuracy: %f' % (epoch, i, num_batch, blue('test'), loss.item(), correct.item()/float(opt.hparamBatchSize)))\n",
    "\n",
    "    torch.save(classifier.state_dict(), '%s/cls_model_%d.pth' % (opt.hparamOutputFolder, epoch))\n",
    "\n",
    "total_correct = 0\n",
    "total_testset = 0\n",
    "for i,data in tqdm(enumerate(test_dataloader, 0)):\n",
    "    points, target = data\n",
    "    target = target[:, 0]\n",
    "    points = points.transpose(2, 1)\n",
    "    points, target = points.cuda(), target.cuda()\n",
    "    classifier = classifier.eval()\n",
    "    pred, _, _ = classifier(points)\n",
    "    pred_choice = pred.data.max(1)[1]\n",
    "    correct = pred_choice.eq(target.data).cpu().sum()\n",
    "    total_correct += correct.item()\n",
    "    total_testset += points.size()[0]\n",
    "\n",
    "print(\"final accuracy {}\".format(total_correct / float(total_testset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.dataloader.DataLoader"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader.__class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 | packaged by conda-forge | (main, Jan 11 2023, 15:15:40) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "773ddf2834531d8a5aed6d7dc0d0d076cb01034543a5015eabafcc7f1dd9fc16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
